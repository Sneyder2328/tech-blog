---
title: "Vibe Coding a Full-Stack AI Chatbot Platform (Part 4): Database Setup with Prisma"
description: "Setting up PostgreSQL with Docker and configuring Prisma ORM with our initial database schema."
pubDate: 2026-01-16
tags: ["tutorial", "ai", "chatbot", "llm", "full-stack", "cursor", "typescript", "prisma", "postgresql", "docker"]
heroImage: "/images/vibe-coding-full-stack-ai-chatbot-part-4-hero-image.jpg"
---

This is Part 4 of the tutorial series. If you haven't read the previous parts, I recommend starting with [Part 1: Introduction](https://blog.sneyderangulo.com/blog/vibe-coding-full-stack-ai-chatbot-part-1).

In [Part 3](https://blog.sneyderangulo.com/blog/vibe-coding-full-stack-ai-chatbot-part-3), we set up the monorepo structure and scaffolded our React and NestJS applications. They run, but there's no database yet. In this part, we'll fix that.

We're going to:
1. Spin up PostgreSQL in Docker
2. Create a shared database package with Prisma
3. Define our initial schema for users, chats, and messages
4. Generate the Prisma client and push the schema

By the end, you'll have a fully typed database layer ready to be consumed by our API.

## Setting Up PostgreSQL with Docker

First, let's get a database running. Create a `docker-compose.yml` in the root directory:

```yaml
services:
  db:
    image: postgres:18-alpine
    container_name: ai-chatbot-database
    restart: unless-stopped
    environment:
      POSTGRES_DB: ai_chatbot
      POSTGRES_USER: ai_chatbot_user
      POSTGRES_PASSWORD: ai_chatbot_password
    ports:
      - "5434:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_chatbot_user -d ai_chatbot"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
```

I'm using port `5434` on the host to avoid conflicts if you already have PostgreSQL running locally on the default `5432`. Feel free to change this if needed.

Start the database:

```bash
docker compose up -d
```

You can verify it's running with:

```bash
docker compose ps
```
You should see the container running and healthy.

## Creating the Database Package

Now let's create a shared package for our database layer. This will contain the Prisma schema and client, and both the API server and any future packages can import from it.

```bash
mkdir -p packages/db
cd packages/db
pnpm init
```

Update the `package.json`:

```json
{
  "name": "db",
  "version": "1.0.0",
  "private": true,
  "main": "./src/index.ts",
  "types": "./src/index.ts",
  "scripts": {
    "db:generate": "prisma generate",
    "db:push": "prisma db push",
    "db:migrate": "prisma migrate dev",
    "db:studio": "prisma studio"
  },
  "packageManager": "pnpm@10.24.0",
  "dependencies": {
    "@prisma/adapter-pg": "^7.2.0",
    "@prisma/client": "^7.2.0",
    "dotenv": "^16.4.5"
  },
  "devDependencies": {
    "prisma": "^7.2.0"
  }
}
```

Install the dependencies and initialize Prisma:

```bash
pnpm add @prisma/client @prisma/adapter-pg dotenv
pnpm add -D prisma
pnpx prisma init
```

This creates a `prisma` directory with a `schema.prisma` file.

## Defining the Schema

Update `prisma/schema.prisma` with our initial schema:

```prisma
generator client {
  provider = "prisma-client"
  output   = "../src/generated/prisma"
}

datasource db {
  provider = "postgresql"
}

model User {
  id        String   @id @default(cuid())
  email     String   @unique
  name      String?
  createdAt DateTime @default(now()) @map("created_at") @db.Timestamp
  updatedAt DateTime @updatedAt @map("updated_at") @db.Timestamp

  chats Chat[]

  @@map("users")
}

model Chat {
  id        String   @id @default(cuid())
  title     String
  userId    String   @map("user_id")
  createdAt DateTime @default(now()) @map("created_at") @db.Timestamp
  updatedAt DateTime @updatedAt @map("updated_at") @db.Timestamp

  user     User      @relation(fields: [userId], references: [id], onDelete: Cascade)
  messages Message[]

  @@map("chats")
}

model Message {
  id        String   @id @default(cuid())
  chatId    String   @map("chat_id")
  role      String   // 'user' | 'assistant'
  content   String
  createdAt DateTime @default(now()) @map("created_at") @db.Timestamp

  chat Chat @relation(fields: [chatId], references: [id], onDelete: Cascade)

  @@map("messages")
}
```

A few things to note about this schema:

- **`@@map("table_name")`**: Maps the Prisma model name to a snake_case table name in the database. This keeps our TypeScript code using PascalCase while the database uses the more conventional snake_case.
- **`@map("column_name")`**: Same idea for column names — `userId` in TypeScript becomes `user_id` in the database.
- **`@db.Timestamp`**: Explicitly uses PostgreSQL's timestamp type for date fields.
- **`onDelete: Cascade`**: When a user is deleted, their chats and messages are automatically deleted too.

The schema gives us the basic models we need: users, chats, and messages. We'll expand this in Part 5 when we add authentication tables (sessions, accounts, etc.), but this is enough to get the database layer working.

## Environment Configuration

Create a `.env` file in the db package:

```env
DATABASE_URL="postgresql://ai_chatbot_user:ai_chatbot_password@localhost:5434/ai_chatbot"

# Database connection pool settings (optional - defaults provided)
DB_MAX_CONNECTIONS=5
DB_MIN_CONNECTIONS=1
DB_CONNECTION_TIMEOUT=10000
DB_IDLE_TIMEOUT=60000
```

The pool configuration variables are optional since the code provides sensible defaults. You can adjust these based on your deployment environment and expected load.

## Creating the Database Client

Now create the entry point at `src/index.ts`:

```typescript
import "dotenv/config"
import { PrismaPg } from "@prisma/adapter-pg"
import { PrismaClient } from "./generated/prisma/client"

const adapter = new PrismaPg({
  connectionString: process.env.DATABASE_URL,
  maxConnections: parseInt(process.env.DB_MAX_CONNECTIONS || '5', 10),
  minConnections: parseInt(process.env.DB_MIN_CONNECTIONS || '1', 10),
  connectionTimeout: parseInt(process.env.DB_CONNECTION_TIMEOUT || '10000', 10),
  idleTimeout: parseInt(process.env.DB_IDLE_TIMEOUT || '60000', 10)
})
export const prisma = new PrismaClient({ adapter })

export * from "./generated/prisma/client"
```

We're using the `@prisma/adapter-pg` driver adapter here, which is required by Prisma version 7 for connecting to PostgreSQL databases. The pool configuration options help optimize connection management, especially important for resource-constrained environments like small VPS deployments.

## Generating and Pushing

Generate the Prisma client:

```bash
pnpm db:generate
```

This creates the typed client in `src/generated/prisma/`. You should add this directory to `.gitignore` since it's generated code:

```bash
echo "src/generated" >> .gitignore
```

Now push the schema to the database:

```bash
pnpm db:push
```

If everything worked, you can verify the tables were created by running:

```bash
pnpm db:studio
```

This opens Prisma Studio in your browser where you can see the empty tables and their structure.

## Adding Root Scripts

Update the root `package.json` to include database scripts:

```json
{
  "scripts": {
    "dev": "turbo dev",
    "build": "turbo build",
    "lint": "turbo lint",
    "lint:fix": "turbo lint:fix",
    "type-check": "turbo type-check",
    "db:generate": "pnpm --filter db db:generate",
    "db:push": "pnpm --filter db db:push",
    "db:migrate": "pnpm --filter db db:migrate",
    "db:studio": "pnpm --filter db db:studio"
  }
}
```

Now you can run database commands from the root:

```bash
pnpm db:studio  # Opens Prisma Studio
pnpm db:push    # Pushes schema changes to the database
```

## What We've Accomplished

- ✅ **PostgreSQL in Docker**: Isolated database environment that matches production
- ✅ **Shared Database Package**: `packages/db` with Prisma schema and client
- ✅ **Initial Schema**: Users, chats, and messages ready to go
- ✅ **Type-Safe Client**: Generated Prisma client with full TypeScript support
- ✅ **Root Scripts**: Easy database management from the monorepo root

The database layer is ready. In **Part 5**, we'll set up authentication with Better Auth, including email/password login and Google OAuth, so users can securely access our application.
